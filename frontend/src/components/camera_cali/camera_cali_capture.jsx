// ìì„¸ ì¸¡ì •
import { useRef, useEffect, useState } from "react";
import { useNavigate } from "react-router-dom";
import { Pose } from "@mediapipe/pose";
import { Camera } from "@mediapipe/camera_utils";

function CameraCaliCapture() {
  const navigate = useNavigate();
  const videoRef = useRef(null);
  const canvasRef = useRef(null);
  const guideCanvasRef = useRef(null);
  const [isCameraOn, setIsCameraOn] = useState(true);

  const [step, setStep] = useState("posture");


  const expectedPoseYMap = {
    // ì •ìì„¸
    posture: {
      leftShoulder: 0.66,
      rightShoulder: 0.66,
    },
    // Tìì„¸
    tpose: {
      leftShoulder: 0.55,
      rightShoulder: 0.55,
      leftWrist: 0.52,
      rightWrist: 0.52,
    },
  };


  // ì¹´ë©”ë¼ ì¼œê¸°
  const startCamera = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { width: { ideal: 1280 }, height: { ideal: 720 } },
      });
      if (videoRef.current) {
        videoRef.current.srcObject = stream;
        setIsCameraOn(true);
      }
    } catch (err) {
      console.error("âŒ ì¹´ë©”ë¼ ì—°ê²° ì‹¤íŒ¨:", err);
    }
  };

  // ì¹´ë©”ë¼ ë„ê¸°
  const stopCamera = () => {
    const stream = videoRef.current?.srcObject;
    if (stream) {
      stream.getTracks().forEach((track) => track.stop());
      videoRef.current.srcObject = null;
      setIsCameraOn(false);
      console.log("ğŸ“´ ì¹´ë©”ë¼ êº¼ì§");

      // ìœ¤ê³½ì„  canvasë„ ì§€ìš°ê¸°
      const guideCanvas = guideCanvasRef.current;
      const ctx = guideCanvas?.getContext("2d");
      if (ctx) {
        ctx.clearRect(0, 0, guideCanvas.width, guideCanvas.height);
      }
    }
  };

  // í˜ì´ì§€ì´ë™ í…ŒìŠ¤íŠ¸ (ì¸ì‹ X)
  useEffect(() => {
  if (isCameraOn) {
    const timer = setTimeout(() => {
      stopCamera();
      alert("ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì¢…ë£Œ (ì„ì‹œ í…ŒìŠ¤íŠ¸)");
      navigate("/login");
    }, 5000);

    return () => clearTimeout(timer); // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
  }
}, [isCameraOn]);

  // ê°€ì´ë“œì„  ê·¸ë¦¬ê¸°
  useEffect(() => {
    const guideCanvas = guideCanvasRef.current;
    if (!guideCanvas) return;
      const ctx = guideCanvas.getContext("2d");
    if (!ctx) return;
    

    const drawGuide = () => {
      if (!guideCanvas || !ctx) return;
      ctx.clearRect(0, 0, guideCanvas.width, guideCanvas.height);
      if (!isCameraOn) return; 

      ctx.lineWidth = 4;

      if (step === "tpose") {
        ctx.strokeStyle = "rgba(255, 165, 0, 0.5)";
        const y = guideCanvas.height * 0.55;

        ctx.beginPath();
        ctx.moveTo(guideCanvas.width * 0.1, y);
        ctx.lineTo(guideCanvas.width * 0.9, y);
        ctx.stroke();

        ctx.beginPath();
        ctx.moveTo(guideCanvas.width / 2, y - 100);
        ctx.lineTo(guideCanvas.width / 2, y + 120);
        ctx.stroke();

      } else if (step === "posture") {
        ctx.strokeStyle = "rgba(0, 200, 255, 0.4)";
        const y = guideCanvas.height * 0.66;

        ctx.beginPath();
        ctx.moveTo(guideCanvas.width * 0.4, y);
        ctx.lineTo(guideCanvas.width * 0.6, y);
        ctx.stroke();

        ctx.beginPath();
        ctx.moveTo(guideCanvas.width / 2, y - 80);
        ctx.lineTo(guideCanvas.width / 2, y + 100);
        ctx.stroke();
      }
    };

    drawGuide();
  }, [step, isCameraOn]);


  // í”„ë ˆì„ ìº¡ì²˜í•´ì„œ ì„œë²„ë¡œ ì „ì†¡
  const sendFrame = async () => {
    const canvas = canvasRef.current;
    const video = videoRef.current;
    if (!canvas || !video) return;

    const ctx = canvas.getContext("2d");

    // ìº¡ì²˜
    ctx.setTransform(1, 0, 0, 1, 0, 0); // transform ì´ˆê¸°í™”
    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

    // ì´ë¯¸ì§€ ì„œë²„ë¡œ ì „ì†¡
    canvas.toBlob(async (blob) => {
      const formData = new FormData();
      formData.append("file", blob, "frame.jpg");

    try {
      console.log("ğŸ“¤ ì´ë¯¸ì§€ ì „ì†¡ ì‹œì‘...");
      const response = await fetch("http://localhost:8000/analyze", {
        method: "POST",
        body: formData,
      });

      if (!response.ok) {
        throw new Error(`ì„œë²„ ì‘ë‹µ ì‹¤íŒ¨: ${response.status}`);
      }

      const result = await response.json();
      console.log("ì„œë²„ ì‘ë‹µ:", result);
    } catch (err) {
      console.error("ì„œë²„ ì „ì†¡ ì‹¤íŒ¨:", err);
    }
    }, "image/jpeg");
  };

  useEffect(() => {
    if (!videoRef.current) return;

    const pose = new Pose({
      locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/pose/${file}`,
    });

    pose.setOptions({
      modelComplexity: 1,
      smoothLandmarks: true,
      minDetectionConfidence: 0.5,
      minTrackingConfidence: 0.5,
    });

    let postureStartTime = null;
    let postureSuccess = false;

    let tposeStartTime = null;
    let tposeSuccess = false;

    pose.onResults((results) => {
      if (!results.poseLandmarks) return;

      const getY = (idx) => results.poseLandmarks[idx]?.y ?? 0;

      // ì •ìì„¸: 3ì´ˆ ì´ìƒ ì—°ì† ìœ ì§€ì‹œ -> ìº¡ì³
      if (step === "posture" && !postureSuccess) {
        const isAligned =
          Math.abs(getY(11) - 0.66) < 0.08 &&
          Math.abs(getY(12) - 0.66) < 0.08;

        if (isAligned) {
          if (!postureStartTime) {
            postureStartTime = Date.now(); // ì²˜ìŒ ê°ì§€ëœ ì‹œê°„ ì €ì¥
          } else {

            const elapsed = Date.now() - postureStartTime;
            const seconds = Math.floor(elapsed / 1000);
            console.log(`ì •ìì„¸ ìœ ì§€ ì¤‘: ${seconds}ì´ˆ`);

            if (elapsed >= 3000) {
              console.log("ì •ìì„¸ 3ì´ˆ ìœ ì§€ ì„±ê³µ!");
              sendFrame();
              postureSuccess = true;

              setTimeout(() => {
                console.log("Tì ìì„¸ë¡œ ì „í™˜");
                setStep("tpose");
              }, 2000);
            }
          }
        } else {
          if (postureStartTime) {
            console.log("ì •ìì„¸ ííŠ¸ëŸ¬ì§! ì‹œê°„ ì´ˆê¸°í™”");
          }
          postureStartTime = null;
        }
      }

      // Tì ìì„¸: 3ì´ˆ ì´ìƒ ì—°ì† ìœ ì§€ì‹œ -> ìº¡ì³
      if (step === "tpose" && !tposeSuccess) {
        const isAligned =
          Math.abs(getY(11) - 0.55) < 0.08 &&
          Math.abs(getY(12) - 0.55) < 0.08 &&
          Math.abs(getY(15) - 0.55) < 0.08 &&
          Math.abs(getY(16) - 0.55) < 0.08;

        if (isAligned) {
          if (!tposeStartTime) {
            tposeStartTime = Date.now(); // ì²˜ìŒ ê°ì§€ëœ ì‹œê°„ ì €ì¥
          } else {

            const elapsed = Date.now() - tposeStartTime;
            const seconds = Math.floor(elapsed / 1000);
            console.log(`Tì ìì„¸ ìœ ì§€ ì¤‘: ${seconds}ì´ˆ`);

            if (elapsed >= 3000) {
              console.log("Tì ìì„¸ 3ì´ˆ ìœ ì§€ ì„±ê³µ!");
              sendFrame();
              tposeSuccess = true;

              setTimeout(() => {
                alert("ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì¢…ë£Œ");
                navigate("/login");
              }, 2000);
            }
          }
        } else {
          if (tposeStartTime) {
            console.log("Tì ìì„¸ ííŠ¸ëŸ¬ì§! ì‹œê°„ ì´ˆê¸°í™”");
          }
          tposeStartTime = null;
        }

      }
    });


    const cam = new Camera(videoRef.current, {
      onFrame: async () => {
        await pose.send({ image: videoRef.current });
      },
      width: 1280,
      height: 720,
    });

    cam.start();
    }, [step]);

  return (
    <div className="w-full flex flex-col items-center py-4 overflow-y-hidden">
      <div className="relative w-[1200px] h-[600px]">
        <video
          ref={videoRef}
          autoPlay
          playsInline
          className={`absolute top-0 left-0 w-full h-full rounded-xl transform scale-x-[-1] 
            ${
            isCameraOn
              ? ""
              : "border-2 border-gray-500 rounded-md border-dashed opacity-40"
          }`}
        />
          {!isCameraOn && (
            <div className="absolute top-[250px] left-1/2 -translate-x-1/2 bg-black px-3 py-1 text-[30px] text-gray-500 opacity-40 rounded-xl">
              ì¹´ë©”ë¼ ì ‘ê·¼ì´ ë¹„í™œì„±í™” ë˜ì–´ ìˆìŠµë‹ˆë‹¤!
            </div>
          )}
        <canvas
          ref={guideCanvasRef}
          width="1200"
          height="600"
          className="absolute top-0 left-0 z-10 pointer-events-none"
        />
        <canvas
          ref={canvasRef}
          width="1200"
          height="600"
          className="hidden"
        />
        {/* ìì„¸ ì¸¡ì • ì•Œë¦¼ UI ì¶”í›„ ìˆ˜ì •
        {step==="start_message" && (
          <div className="fade-in-out absolute top-1/2 left-1/2 -translate-x-1/2 -translate-y-1/2 bg-white/80 text-xl font-semibold px-6 py-3 rounded-xl shadow">
            ì •ìì„¸ ì¸¡ì •ì„ ì‹œì‘í•©ë‹ˆë‹¤!
          </div>
        )}
        {step === "message" && (
          <div className="fade-in-out absolute top-1/2 left-1/2 -translate-x-1/2 -translate-y-1/2 bg-white/80 text-xl font-semibold px-6 py-3 rounded-xl shadow">
            ì •ìì„¸ ì™„ë£Œ! Tì ìì„¸ë¡œ ì´ë™í•©ë‹ˆë‹¤.
          </div>
        )}
        {step==="end_message" && (
          <div className="fade-in-out absolute top-1/2 left-1/2 -translate-x-1/2 -translate-y-1/2 bg-white/80 text-xl font-semibold px-6 py-3 rounded-xl shadow">
            Tì ìì„¸ ì™„ë£Œ! ìì„¸ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ì„ ì¢…ë£Œí•©ë‹ˆë‹¤!
          </div>
        )}*/}

      </div>

      <div className="flex flex-row justify-around gap-4">
        <button
          onClick={isCameraOn ? stopCamera : startCamera}
          className={`mt-4 px-6 py-2 ${
            isCameraOn
              ? "bg-red-600 hover:bg-red-700"
              : "bg-green-600 hover:bg-green-700"
          } text-white rounded-lg shadow`}
        >
          {isCameraOn ? "ì¹´ë©”ë¼ ë„ê¸°" : "ì¹´ë©”ë¼ ì¼œê¸°"}
        </button>
      </div>
    </div>
  );
}

export default CameraCaliCapture;
