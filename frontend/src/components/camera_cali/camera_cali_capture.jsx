// ìì„¸ ì¸¡ì •
import { useRef, useEffect, useState } from "react";
import { useNavigate } from "react-router-dom";
import { Pose } from "@mediapipe/pose";
import { Camera } from "@mediapipe/camera_utils";
import { isPostureAligned, isTPoseAligned } from "../../utils/pose_check";

function CameraCaliCapture() {
  const navigate = useNavigate();
  const videoRef = useRef(null);
  const canvasRef = useRef(null);
  const guideCanvasRef = useRef(null);
  const [isCameraOn, setIsCameraOn] = useState(true);

  const [step, setStep] = useState("posture");
  const [message, setMessage] = useState(""); // ìƒíƒœ ë©”ì‹œì§€ í‘œì‹œ

  const token = sessionStorage.getItem("accessToken");

  const postureStableCount = useRef(0);
  const tposeStableCount = useRef(0);
  const successFlags = useRef({ posture: false, tpose: false });


  // ì¹´ë©”ë¼ ì¼œê¸°
  const startCamera = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { width: { ideal: 1280 }, height: { ideal: 720 } },
      });
      if (videoRef.current) {
        videoRef.current.srcObject = stream;
        setIsCameraOn(true);
      }
    } catch (err) {
      console.error("âŒ ì¹´ë©”ë¼ ì—°ê²° ì‹¤íŒ¨:", err);
    }
  };

  // ì¹´ë©”ë¼ ë„ê¸°
  const stopCamera = () => {
    const stream = videoRef.current?.srcObject;
    if (stream) {
      stream.getTracks().forEach((track) => track.stop());
      videoRef.current.srcObject = null;
      setIsCameraOn(false);
      console.log("ğŸ“´ ì¹´ë©”ë¼ êº¼ì§");

      // ìœ¤ê³½ì„  canvasë„ ì§€ìš°ê¸°
      const guideCanvas = guideCanvasRef.current;
      const ctx = guideCanvas?.getContext("2d");
      if (ctx) {
        ctx.clearRect(0, 0, guideCanvas.width, guideCanvas.height);
      }
    }
  };

  // ğŸ“Œ í”„ë ˆì„ ì „ì†¡
  const sendFrame = async () => {
    const canvas = canvasRef.current;
    const video = videoRef.current;
    if (!canvas || !video) return null;

    const ctx = canvas.getContext("2d");
    ctx?.setTransform(1, 0, 0, 1, 0, 0);
    ctx?.drawImage(video, 0, 0, canvas.width, canvas.height);

    return new Promise((resolve) => {
      canvas.toBlob(async (blob) => {
        if (!blob) return resolve(null);

        const formData = new FormData();
        formData.append("file", blob, "frame.jpg");
        formData.append("pose_type", step);

        try {
          const res = await fetch("http://localhost:8000/analyze", {
            method: "POST",
            headers: { Authorization: "Bearer " + token },
            body: formData,
          });

          const result = await res.json();
          console.log("ğŸ“¥ ì„œë²„ ì‘ë‹µ:", result);
          resolve(result);
        } catch (err) {
          console.error("âŒ ì „ì†¡ ì‹¤íŒ¨:", err);
          resolve(null);
        }
      }, "image/jpeg");
    });
  };

  // ğŸ“Œ ëª©í‘œ í”„ë ˆì„ ìˆ˜ ë„ë‹¬í•  ë•Œê¹Œì§€ ë°˜ë³µ ì „ì†¡
  const sendUntilCollected = async (target = 30, interval = 300) => {
    let collected = 0;
    let result = null;

        if (result?.current_pose) {
      console.log("ğŸ“ current_pose:", result.current_pose);
    }

    while (collected < target) {
      result = await sendFrame();
      if (result?.collected_frames !== undefined) {
        collected = result.collected_frames;
        console.log(`âœ… ëˆ„ì  ìœ íš¨ í”„ë ˆì„ ìˆ˜: ${collected}/${target}`);
      } else {
        console.warn("âš ï¸ ì‘ë‹µì— collected_frames ì—†ìŒ ë˜ëŠ” ì‹¤íŒ¨");
      }
      await new Promise((r) => setTimeout(r, interval));
    }

    return result;
  };

  // ğŸ“Œ Mediapipe Pose ì„¸íŒ…
  useEffect(() => {
    if (!videoRef.current) return;

    const pose = new Pose({
      locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/pose/${file}`,
    });

    pose.setOptions({
      modelComplexity: 1,
      smoothLandmarks: true,
      minDetectionConfidence: 0.5,
      minTrackingConfidence: 0.5,
    });

    pose.onResults(async (results) => {
      if (!results.poseLandmarks) return;
      const landmarks = results.poseLandmarks;

      if (step === "posture" && !successFlags.current.posture) {
        if (isPostureAligned(landmarks)) {
          postureStableCount.current++;
          setMessage("ì •ìì„¸ ì¸ì‹ì„ ì‹œì‘í•©ë‹ˆë‹¤! ë‹¤ìŒ ì•ˆë‚´ê¹Œì§€ ìì„¸ë¥¼ ìœ ì§€í•´ì£¼ì„¸ìš”!");

          if (postureStableCount.current >= 30) {
            successFlags.current.posture = true;
            const result = await sendUntilCollected(30, 300);

            if (result?.message) setMessage(result.message);
            if (result?.current_pose) setStep(result.current_pose); // ğŸ’¡ ë°± ê¸°ì¤€ìœ¼ë¡œ ë‹¤ìŒ ë‹¨ê³„
          }
        } else {
          postureStableCount.current = 0;
        }
      }

      if (step === "tpose" && !successFlags.current.tpose) {
        if (isTPoseAligned(landmarks)) {
          tposeStableCount.current++;
          setMessage("Tì ìì„¸ ì¸ì‹ì„ ì‹œì‘í•©ë‹ˆë‹¤! ë‹¤ìŒ ì•ˆë‚´ê¹Œì§€ ìì„¸ë¥¼ ìœ ì§€í•´ì£¼ì„¸ìš”!");

          if (tposeStableCount.current >= 30) {
            successFlags.current.tpose = true;
            const result = await sendUntilCollected(30, 500);

            if (result?.message) setMessage(result.message);

            if (result?.current_pose === "done") {
              setMessage("ğŸ‰ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì¢…ë£Œ");
              setTimeout(() => navigate("/login"), 2000);
            } else {
              setStep(result.current_pose); // í˜¹ì‹œ ë‹¤ë¥¸ ë‹¨ê³„ê°€ ìˆìœ¼ë©´
            }
          }
        } else {
          tposeStableCount.current = 0;
        }
      }
    });




    let frameCount = 0;
    let lastTimestamp = performance.now();

    const cam = new Camera(videoRef.current, {
      onFrame: async () => {
        frameCount++;
        const now = performance.now();
        const elapsed = now - lastTimestamp;

        if (elapsed >= 1000) {
          console.log(`FPS: ${frameCount} frames/sec`);
          frameCount = 0;
          lastTimestamp = now;
        }

        try {
          await pose.send({ image: videoRef.current });
        } catch (err) {
          console.error("âŒ pose.send ì¤‘ ì—ëŸ¬:", err);
        }
      },
    });

    cam.start();
  }, [step]);


    // ğŸ“Œ ê°€ì´ë“œì„  ê·¸ë¦¬ê¸°
  useEffect(() => {
    const guideCanvas = guideCanvasRef.current;
    const ctx = guideCanvas?.getContext("2d");
    if (!guideCanvas || !ctx) return;

    let animationFrameId;

    const drawGuide = () => {
      ctx.clearRect(0, 0, guideCanvas.width, guideCanvas.height);
      if (!isCameraOn) return;

      ctx.lineWidth = 4;

      if (step === "tpose") {
        ctx.strokeStyle = "rgba(255, 165, 0, 0.5)";
        const y = guideCanvas.height * 0.55;
        ctx.beginPath();
        ctx.moveTo(guideCanvas.width * 0.1, y);
        ctx.lineTo(guideCanvas.width * 0.9, y);
        ctx.stroke();
        ctx.beginPath();
        ctx.moveTo(guideCanvas.width / 2, y - 100);
        ctx.lineTo(guideCanvas.width / 2, y + 120);
        ctx.stroke();
      } else if (step === "posture") {
        ctx.strokeStyle = "rgba(0, 200, 255, 0.4)";
        const y = guideCanvas.height * 0.5;
        ctx.beginPath();
        ctx.moveTo(guideCanvas.width * 0.4, y);
        ctx.lineTo(guideCanvas.width * 0.6, y);
        ctx.stroke();
        ctx.beginPath();
        ctx.moveTo(guideCanvas.width / 2, y - 80);
        ctx.lineTo(guideCanvas.width / 2, y + 100);
        ctx.stroke();
      }

      animationFrameId = requestAnimationFrame(drawGuide);
    };

    drawGuide();

    return () => cancelAnimationFrame(animationFrameId);
  }, [step, isCameraOn]);


  return (
    <div className="w-full flex flex-col items-center py-4 overflow-y-hidden">
      <div className="relative w-[1200px] h-[675px]">
        <video
          ref={videoRef}
          autoPlay
          playsInline
          className={`absolute top-0 left-0 w-full h-full rounded-xl transform scale-x-[-1] 
            ${
            isCameraOn
              ? ""
              : "border-2 border-gray-500 rounded-md border-dashed opacity-40"
          }`}
        />
          {!isCameraOn && (
            <div className="absolute top-[250px] left-1/2 -translate-x-1/2 bg-black px-3 py-1 text-[30px] text-gray-500 opacity-40 rounded-xl">
              ì¹´ë©”ë¼ ì ‘ê·¼ì´ ë¹„í™œì„±í™” ë˜ì–´ ìˆìŠµë‹ˆë‹¤!
            </div>
          )}
        <canvas
          ref={guideCanvasRef}
          width="640"
          height="360"
          style={{ width: "1200px", height: "675px" }}
          className="absolute top-0 left-0 z-10 pointer-events-none"
        />
        <canvas
          ref={canvasRef}
          width="1200"
          height="675"
          className="hidden"
        />

      </div>

      <div className="mt-4 text-lg font-semibold text-blue-600">{message}</div>

      <div className="flex flex-row justify-around gap-4">
        <button
          onClick={isCameraOn ? stopCamera : startCamera}
          className={`mt-4 px-6 py-2 ${
            isCameraOn
              ? "bg-red-600 hover:bg-red-700"
              : "bg-green-600 hover:bg-green-700"
          } text-white rounded-lg shadow`}
        >
          {isCameraOn ? "ì¹´ë©”ë¼ ë„ê¸°" : "ì¹´ë©”ë¼ ì¼œê¸°"}
        </button>
      </div>
    </div>
  );
}

export default CameraCaliCapture;
